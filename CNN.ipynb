{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOTftZvAAb4aSODP1DN0Ud"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRar6RNJ7WWY"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "lqOlparY7mpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "70NIZGBk8OgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "eR_myU908Ws_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "9PrtNuDh8h92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,Y_train),(X_valid,Y_valid) = mnist.load_data()  #load data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pBk99VD80lG",
        "outputId": "217cb51a-4626-440f-f172-2c05b988e932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape(60000,784).astype('float32')     #processing of data\n",
        "X_valid =X_valid.reshape(10000,784).astype('float32')  \n"
      ],
      "metadata": {
        "id": "c94a_iPFBTdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train/=255    #normalisation\n",
        "X_valid/=255   "
      ],
      "metadata": {
        "id": "W_Z6rtRJ85F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ricz6Co8ElRz",
        "outputId": "bf8683b7-4ca3-40bf-f252-b8172f267726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import utils as np_utils              #convert the labels to one hot representation\n",
        "n_classes=10\n",
        "Y_train=keras.utils.np_utils.to_categorical(Y_train,n_classes)\n",
        "Y_valid=keras.utils.np_utils.to_categorical(Y_valid,n_classes)"
      ],
      "metadata": {
        "id": "qWcpdsR2Ezj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_valid[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFWhuaQsFT6M",
        "outputId": "04477eb7-49ee-4c73-f491-f799313730f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()   #defining model"
      ],
      "metadata": {
        "id": "rD7Z3M1mFjN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(64,activation='sigmoid',input_shape=(784,)))   #adding the dense layer"
      ],
      "metadata": {
        "id": "N9OVeiAYF8vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(10,activation='softmax'))  #adding the final layer"
      ],
      "metadata": {
        "id": "5zm5NLD5Gq7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PeedpzHHBys",
        "outputId": "4fdec7fe-2582-46b1-9712-cdc13b9efc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error',optimizer=SGD(learning_rate=0.01),metrics=['accuracy'])  #compile the network\n"
      ],
      "metadata": {
        "id": "rzHCVdV8HUVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,Y_train,batch_size=128,epochs=150,verbose=1)   #train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZyx1PgeIWP8",
        "outputId": "851d8f77-e261-4657-8fee-d2467f0d30dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "469/469 [==============================] - 2s 2ms/step - loss: 0.0931 - accuracy: 0.1749\n",
            "Epoch 2/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.1953\n",
            "Epoch 3/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.2144\n",
            "Epoch 4/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.2223\n",
            "Epoch 5/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.2278\n",
            "Epoch 6/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.2341\n",
            "Epoch 7/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.2425\n",
            "Epoch 8/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.2489\n",
            "Epoch 9/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.2575\n",
            "Epoch 10/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0871 - accuracy: 0.2616\n",
            "Epoch 11/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.2681\n",
            "Epoch 12/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.2734\n",
            "Epoch 13/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.2767\n",
            "Epoch 14/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.2792\n",
            "Epoch 15/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0852 - accuracy: 0.2838\n",
            "Epoch 16/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.2858\n",
            "Epoch 17/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.2882\n",
            "Epoch 18/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.2903\n",
            "Epoch 19/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.2943\n",
            "Epoch 20/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.2976\n",
            "Epoch 21/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.3003\n",
            "Epoch 22/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.3044\n",
            "Epoch 23/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.3088\n",
            "Epoch 24/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.3135\n",
            "Epoch 25/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0812 - accuracy: 0.3195\n",
            "Epoch 26/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.3240\n",
            "Epoch 27/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.3288\n",
            "Epoch 28/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.3353\n",
            "Epoch 29/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.3412\n",
            "Epoch 30/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0792 - accuracy: 0.3467\n",
            "Epoch 31/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0787 - accuracy: 0.3531\n",
            "Epoch 32/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.3596\n",
            "Epoch 33/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.3667\n",
            "Epoch 34/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0775 - accuracy: 0.3742\n",
            "Epoch 35/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0771 - accuracy: 0.3828\n",
            "Epoch 36/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.3898\n",
            "Epoch 37/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.3972\n",
            "Epoch 38/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0758 - accuracy: 0.4069\n",
            "Epoch 39/150\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0754 - accuracy: 0.4157\n",
            "Epoch 40/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.4247\n",
            "Epoch 41/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0746 - accuracy: 0.4328\n",
            "Epoch 42/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0742 - accuracy: 0.4432\n",
            "Epoch 43/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.4541\n",
            "Epoch 44/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.4625\n",
            "Epoch 45/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0730 - accuracy: 0.4717\n",
            "Epoch 46/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.4816\n",
            "Epoch 47/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.4904\n",
            "Epoch 48/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.4991\n",
            "Epoch 49/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0713 - accuracy: 0.5077\n",
            "Epoch 50/150\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0709 - accuracy: 0.5167\n",
            "Epoch 51/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0705 - accuracy: 0.5249\n",
            "Epoch 52/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0701 - accuracy: 0.5327\n",
            "Epoch 53/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.5413\n",
            "Epoch 54/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.5488\n",
            "Epoch 55/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.5558\n",
            "Epoch 56/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0685 - accuracy: 0.5638\n",
            "Epoch 57/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0681 - accuracy: 0.5700\n",
            "Epoch 58/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0677 - accuracy: 0.5777\n",
            "Epoch 59/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.5839\n",
            "Epoch 60/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0669 - accuracy: 0.5898\n",
            "Epoch 61/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.5957\n",
            "Epoch 62/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0661 - accuracy: 0.6010\n",
            "Epoch 63/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.6061\n",
            "Epoch 64/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0652 - accuracy: 0.6124\n",
            "Epoch 65/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0648 - accuracy: 0.6178\n",
            "Epoch 66/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.6238\n",
            "Epoch 67/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0640 - accuracy: 0.6279\n",
            "Epoch 68/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.6334\n",
            "Epoch 69/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0632 - accuracy: 0.6383\n",
            "Epoch 70/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.6427\n",
            "Epoch 71/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.6474\n",
            "Epoch 72/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0620 - accuracy: 0.6512\n",
            "Epoch 73/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.6551\n",
            "Epoch 74/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.6590\n",
            "Epoch 75/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0607 - accuracy: 0.6626\n",
            "Epoch 76/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0603 - accuracy: 0.6671\n",
            "Epoch 77/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0599 - accuracy: 0.6704\n",
            "Epoch 78/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.6737\n",
            "Epoch 79/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0591 - accuracy: 0.6769\n",
            "Epoch 80/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.6803\n",
            "Epoch 81/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.6834\n",
            "Epoch 82/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.6862\n",
            "Epoch 83/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.6890\n",
            "Epoch 84/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.6918\n",
            "Epoch 85/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.6945\n",
            "Epoch 86/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.6970\n",
            "Epoch 87/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.6995\n",
            "Epoch 88/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0555 - accuracy: 0.7024\n",
            "Epoch 89/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0551 - accuracy: 0.7048\n",
            "Epoch 90/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.7071\n",
            "Epoch 91/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.7097\n",
            "Epoch 92/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.7122\n",
            "Epoch 93/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.7146\n",
            "Epoch 94/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.7169\n",
            "Epoch 95/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.7188\n",
            "Epoch 96/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0524 - accuracy: 0.7212\n",
            "Epoch 97/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.7232\n",
            "Epoch 98/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.7252\n",
            "Epoch 99/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.7273\n",
            "Epoch 100/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.7293\n",
            "Epoch 101/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.7309\n",
            "Epoch 102/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.7329\n",
            "Epoch 103/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0499 - accuracy: 0.7350\n",
            "Epoch 104/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.7368\n",
            "Epoch 105/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.7382\n",
            "Epoch 106/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0488 - accuracy: 0.7401\n",
            "Epoch 107/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0485 - accuracy: 0.7417\n",
            "Epoch 108/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.7433\n",
            "Epoch 109/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.7449\n",
            "Epoch 110/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.7467\n",
            "Epoch 111/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.7481\n",
            "Epoch 112/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.7497\n",
            "Epoch 113/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.7512\n",
            "Epoch 114/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.7526\n",
            "Epoch 115/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0459 - accuracy: 0.7540\n",
            "Epoch 116/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.7555\n",
            "Epoch 117/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.7565\n",
            "Epoch 118/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.7578\n",
            "Epoch 119/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.7593\n",
            "Epoch 120/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.7604\n",
            "Epoch 121/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.7616\n",
            "Epoch 122/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.7630\n",
            "Epoch 123/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.7648\n",
            "Epoch 124/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.7660\n",
            "Epoch 125/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.7673\n",
            "Epoch 126/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.7688\n",
            "Epoch 127/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.7702\n",
            "Epoch 128/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.7719\n",
            "Epoch 129/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.7734\n",
            "Epoch 130/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.7748\n",
            "Epoch 131/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.7764\n",
            "Epoch 132/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.7780\n",
            "Epoch 133/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.7798\n",
            "Epoch 134/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.7814\n",
            "Epoch 135/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.7834\n",
            "Epoch 136/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.7850\n",
            "Epoch 137/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0399 - accuracy: 0.7871\n",
            "Epoch 138/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0397 - accuracy: 0.7893\n",
            "Epoch 139/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.7909\n",
            "Epoch 140/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.7928\n",
            "Epoch 141/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.7942\n",
            "Epoch 142/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.7963\n",
            "Epoch 143/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.7978\n",
            "Epoch 144/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.7995\n",
            "Epoch 145/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.8012\n",
            "Epoch 146/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.8029\n",
            "Epoch 147/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.8047\n",
            "Epoch 148/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.8065\n",
            "Epoch 149/150\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0372 - accuracy: 0.8080\n",
            "Epoch 150/150\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.8094\n"
          ]
        }
      ]
    }
  ]
}